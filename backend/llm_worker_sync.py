import requests
import json
import time
from datetime import datetime, timedelta
from sqlalchemy import create_engine, select
from sqlalchemy.orm import sessionmaker
from models import Word, LLM, WordSerp, Company, BrandProject, BrandMention, Competitor
import logging
from config_simple import settings
import re

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SyncLLMWorker:
    """–ü–æ–ª–Ω–æ—Å—Ç—å—é —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤–æ—Ä–∫–µ—Ä –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è SERP –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.timeout = 60
        
        # –°–æ–∑–¥–∞–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î
        db_url = settings.database_url.replace("postgresql+asyncpg://", "postgresql://")
        self.engine = create_engine(db_url)
        self.SessionLocal = sessionmaker(bind=self.engine)
    
    def get_serp_from_openai_sync(self, word: str) -> str:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ SERP –¥–∞–Ω–Ω—ã—Ö –æ—Ç OpenAI"""
        try:
            prompt = f"""
            –ü—Ä–µ–¥—Å—Ç–∞–≤—å, —á—Ç–æ —Ç—ã –ø–æ–∏—Å–∫–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞. –î–ª—è –∑–∞–ø—Ä–æ—Å–∞ "{word}" –≤—ã–¥–∞–π —Ç–æ–ø-10 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
            1. –ó–∞–≥–æ–ª–æ–≤–æ–∫ - –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
            2. –ó–∞–≥–æ–ª–æ–≤–æ–∫ - –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
            ...
            
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–º–∏ –∏ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–º–∏.
            """
            
            headers = {
                "Authorization": f"Bearer {settings.openai_api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": "gpt-3.5-turbo",
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 1000,
                "temperature": 0.7
            }
            
            response = self.session.post(
                "https://api.openai.com/v1/chat/completions",
                headers=headers,
                json=data
            )
            
            if response.status_code == 200:
                result = response.json()
                return result["choices"][0]["message"]["content"]
            else:
                logger.error(f"OpenAI API error: {response.status_code} - {response.text}")
                return self.get_mock_serp(word, "openai")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ OpenAI: {e}")
            return self.get_mock_serp(word, "openai")
    
    def get_mock_serp(self, word: str, llm_name: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è mock SERP –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        mock_results = [
            f"1. {word.title()} Official Website - –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Å–∞–π—Ç {word}",
            f"2. Wikipedia: {word} - –≠–Ω—Ü–∏–∫–ª–æ–ø–µ–¥–∏—á–µ—Å–∫–∞—è —Å—Ç–∞—Ç—å—è –æ {word}",
            f"3. {word} Reviews - –û—Ç–∑—ã–≤—ã –∏ —Ä–µ–π—Ç–∏–Ω–≥–∏ {word}",
            f"4. Buy {word} Online - –ò–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω {word}",
            f"5. {word} News - –ü–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –æ {word}",
            f"6. {word} Tutorial - –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é {word}",
            f"7. {word} Comparison - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ {word} —Å –∞–Ω–∞–ª–æ–≥–∞–º–∏",
            f"8. {word} Forum - –§–æ—Ä—É–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π {word}",
            f"9. {word} Support - –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ {word}",
            f"10. {word} Blog - –ë–ª–æ–≥ –æ {word}"
        ]
        
        return "\n".join(mock_results) + f"\n\n[Generated by {llm_name}]"

    def extract_companies_simple(self, serp_content: str) -> list:
        """–ü—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–π –∏–∑ SERP –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        companies = []
        
        # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –∫–æ–º–ø–∞–Ω–∏–π
        lines = serp_content.split('\n')
        for line in lines:
            # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏ —Å —Ç–æ—á–∫–∞–º–∏ (—Å–ø–∏—Å–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤)
            if re.match(r'^\d+\.', line.strip()):
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–æ—Å–ª–µ –Ω–æ–º–µ—Ä–∞
                match = re.search(r'^\d+\.\s*([^-]+)', line.strip())
                if match:
                    company_name = match.group(1).strip()
                    if len(company_name) > 2 and len(company_name) < 100:
                        companies.append(company_name)
        
        return companies[:10]  # –ú–∞–∫—Å–∏–º—É–º 10 –∫–æ–º–ø–∞–Ω–∏–π

    def process_word_with_llm(self, word: Word, llm: LLM, db_session) -> bool:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Å–ª–æ–≤–∞ —Å –æ–¥–Ω–∏–º LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–º"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª –ª–∏ —É–∂–µ –∑–∞–ø—Ä–æ—Å –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 –Ω–µ–¥–µ–ª–∏
            from datetime import timezone
            two_weeks_ago = datetime.now(timezone.utc) - timedelta(days=14)
            
            existing_serp = db_session.scalar(
                select(WordSerp).where(
                    WordSerp.word_id == word.uuid,
                    WordSerp.llm_id == llm.uuid,
                    WordSerp.create_time > two_weeks_ago
                )
            )
            
            if existing_serp:
                logger.info(f"SERP –¥–ª—è —Å–ª–æ–≤–∞ '{word.name}' –∏ LLM '{llm.name}' —É–∂–µ –æ–±–Ω–æ–≤–ª–µ–Ω")
                return False
            
            logger.info(f"–ü–æ–ª—É—á–∞–µ–º SERP –¥–ª—è '{word.name}' –æ—Ç {llm.name}")
            
            # –ü–æ–ª—É—á–∞–µ–º SERP –¥–∞–Ω–Ω—ã–µ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
            if llm.name.lower() == "openai" and hasattr(settings, 'openai_api_key'):
                serp_content = self.get_serp_from_openai_sync(word.name)
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º mock –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
                serp_content = self.get_mock_serp(word.name, llm.name)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç SERP
            word_serp = WordSerp(
                content=serp_content,
                llm_id=llm.uuid,
                word_id=word.uuid,
                create_time=datetime.now(timezone.utc)
            )
            
            db_session.add(word_serp)
            db_session.flush()  # –ü–æ–ª—É—á–∞–µ–º ID –¥–ª—è —Å–≤—è–∑–∏ —Å –∫–æ–º–ø–∞–Ω–∏—è–º–∏
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–º–ø–∞–Ω–∏–∏ –∏–∑ SERP
            companies = self.extract_companies_simple(serp_content)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–º–ø–∞–Ω–∏–∏
            for company_name in companies:
                company = Company(
                    name=company_name,
                    serp_id=word_serp.uuid
                )
                db_session.add(company)
            
            db_session.commit()
            logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(companies)} –∫–æ–º–ø–∞–Ω–∏–π –∏–∑ SERP –¥–ª—è —Å–ª–æ–≤–∞ '{word.name}'")
            
            return True
            
        except Exception as e:
            db_session.rollback()
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–ª–æ–≤–∞ '{word.name}' —Å LLM '{llm.name}': {e}")
            return False

    def analyze_brand_mentions_simple(self, serp_content: str, brand_name: str, competitor_names: list) -> dict:
        """–ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –±—Ä–µ–Ω–¥–æ–≤ –±–µ–∑ LLM"""
        content_lower = serp_content.lower()
        brand_lower = brand_name.lower()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –±—Ä–µ–Ω–¥–∞
        brand_mentioned = brand_lower in content_lower
        brand_position = None
        if brand_mentioned:
            # –ò—â–µ–º –ø–æ–∑–∏—Ü–∏—é –≤ —Å–ø–∏—Å–∫–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            lines = serp_content.split('\n')
            for i, line in enumerate(lines, 1):
                if brand_lower in line.lower():
                    brand_position = i
                    break
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
        competitor_mentioned = False
        mentioned_competitor = None
        competitor_position = None
        
        for competitor in competitor_names:
            if competitor.lower() in content_lower:
                competitor_mentioned = True
                mentioned_competitor = competitor
                # –ò—â–µ–º –ø–æ–∑–∏—Ü–∏—é –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞
                lines = serp_content.split('\n')
                for i, line in enumerate(lines, 1):
                    if competitor.lower() in line.lower():
                        competitor_position = i
                        break
                break
        
        return {
            "brand_mentioned": brand_mentioned,
            "competitor_mentioned": competitor_mentioned,
            "mentioned_competitor": mentioned_competitor,
            "brand_position": brand_position,
            "competitor_position": competitor_position,
            "confidence": 90
        }

    def analyze_brand_mentions_for_serp(self, serp: WordSerp, db_session) -> bool:
        """–ê–Ω–∞–ª–∏–∑ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –±—Ä–µ–Ω–¥–æ–≤ –≤ SERP —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ brand –ø—Ä–æ–µ–∫—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å —Å–≤—è–∑–∞–Ω—ã —Å —ç—Ç–∏–º —Å–ª–æ–≤–æ–º
            word = db_session.scalar(select(Word).where(Word.uuid == serp.word_id))
            if not word or not word.group_id:
                return False
            
            # –ò—â–µ–º brand –ø—Ä–æ–µ–∫—Ç –¥–ª—è —ç—Ç–æ–π –≥—Ä—É–ø–ø—ã
            brand_project = db_session.scalar(
                select(BrandProject).where(BrandProject.word_group_id == word.group_id)
            )
            
            if not brand_project:
                return False  # –≠—Ç–æ –Ω–µ brand –ø—Ä–æ–µ–∫—Ç
            
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞
            competitors = db_session.execute(
                select(Competitor).where(Competitor.project_id == brand_project.uuid)
            )
            competitor_names = [comp.name for comp in competitors.scalars().all()]
            
            # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –±–µ–∑ LLM
            analysis_result = self.analyze_brand_mentions_simple(
                serp.content,
                brand_project.brand_name,
                competitor_names
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
            brand_mention = BrandMention(
                serp_id=serp.uuid,
                project_id=brand_project.uuid,
                brand_mentioned=1 if analysis_result.get("brand_mentioned", False) else 0,
                competitor_mentioned=1 if analysis_result.get("competitor_mentioned", False) else 0,
                mentioned_competitor=analysis_result.get("mentioned_competitor"),
                brand_position=analysis_result.get("brand_position"),
                competitor_position=analysis_result.get("competitor_position"),
                analysis_confidence=analysis_result.get("confidence", 100)
            )
            
            db_session.add(brand_mention)
            db_session.commit()
            
            logger.info(f"–ê–Ω–∞–ª–∏–∑ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω –¥–ª—è SERP {serp.uuid}")
            return True
            
        except Exception as e:
            db_session.rollback()
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –¥–ª—è SERP {serp.uuid}: {e}")
            return False

    def run_worker_cycle(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –≤–æ—Ä–∫–µ—Ä–∞"""
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ —Ü–∏–∫–ª–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è SERP –¥–∞–Ω–Ω—ã—Ö")
        
        with self.SessionLocal() as db_session:
            try:
                # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ —Å–ª–æ–≤–∞
                words = list(db_session.execute(
                    select(Word).where(Word.status == 1)
                ).scalars().all())
                
                # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã
                llms = list(db_session.execute(
                    select(LLM).where(LLM.is_active == 1)
                ).scalars().all())
                
                logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(words)} —Å–ª–æ–≤ –∏ {len(llms)} LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤")
                
                processed_count = 0
                for word in words:
                    for llm in llms:
                        success = self.process_word_with_llm(word, llm, db_session)
                        if success:
                            processed_count += 1
                            
                            # –ü–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ SERP, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –±—Ä–µ–Ω–¥–æ–≤
                            latest_serp = db_session.scalar(
                                select(WordSerp)
                                .where(WordSerp.word_id == word.uuid)
                                .where(WordSerp.llm_id == llm.uuid)
                                .order_by(WordSerp.create_time.desc())
                                .limit(1)
                            )
                            
                            if latest_serp:
                                self.analyze_brand_mentions_for_serp(latest_serp, db_session)
                
                logger.info(f"‚úÖ –¶–∏–∫–ª –∑–∞–≤–µ—Ä—à–µ–Ω. –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_count} –∫–æ–º–±–∏–Ω–∞—Ü–∏–π —Å–ª–æ–≤–æ-LLM")
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ –≤–æ—Ä–∫–µ—Ä–∞: {e}")

    def run_continuous(self, interval_hours: int = 24 * 14):  # 2 –Ω–µ–¥–µ–ª–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        """–ù–µ–ø—Ä–µ—Ä—ã–≤–Ω–∞—è —Ä–∞–±–æ—Ç–∞ –≤–æ—Ä–∫–µ—Ä–∞ —Å –∑–∞–¥–∞–Ω–Ω—ã–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º"""
        logger.info(f"–ó–∞–ø—É—Å–∫ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ –≤–æ—Ä–∫–µ—Ä–∞ —Å –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º {interval_hours} —á–∞—Å–æ–≤")
        
        while True:
            try:
                self.run_worker_cycle()
                
                # –ñ–¥–µ–º –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ü–∏–∫–ª–∞
                wait_seconds = interval_hours * 3600
                logger.info(f"–û–∂–∏–¥–∞–Ω–∏–µ {interval_hours} —á–∞—Å–æ–≤ –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ü–∏–∫–ª–∞")
                time.sleep(wait_seconds)
                
            except KeyboardInterrupt:
                logger.info("–ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –≤–æ—Ä–∫–µ—Ä–∞")
                break
            except Exception as e:
                logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤–æ—Ä–∫–µ—Ä–∞: {str(e)}")
                # –ñ–¥–µ–º 1 —á–∞—Å –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π
                time.sleep(3600)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –≤–æ—Ä–∫–µ—Ä–∞
sync_llm_worker = SyncLLMWorker()

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –≤–æ—Ä–∫–µ—Ä–∞
def start_sync_worker():
    """–ó–∞–ø—É—Å–∫ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –≤–æ—Ä–∫–µ—Ä–∞"""
    sync_llm_worker.run_continuous()

if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ –≤–æ—Ä–∫–µ—Ä–∞ –Ω–∞–ø—Ä—è–º—É—é
    start_sync_worker()
