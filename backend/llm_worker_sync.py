import requests
import json
import time
from datetime import datetime, timedelta
from sqlalchemy import create_engine, select
from sqlalchemy.orm import sessionmaker
from models import Word, LLM, WordSerp, Company, BrandProject, BrandMention, Competitor
import logging
from config_simple import settings
import re

# Настройка логирования
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SyncLLMWorker:
    """Полностью синхронный воркер для автоматического обновления SERP данных"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.timeout = 60
        
        # Создаем синхронное подключение к БД
        db_url = settings.database_url.replace("postgresql+asyncpg://", "postgresql://")
        self.engine = create_engine(db_url)
        self.SessionLocal = sessionmaker(bind=self.engine)
    
    def get_serp_from_openai_sync(self, word: str) -> str:
        """Синхронное получение SERP данных от OpenAI"""
        try:
            prompt = f"""
            Представь, что ты поисковая система. Для запроса "{word}" выдай топ-10 результатов поиска в формате:
            1. Заголовок - краткое описание
            2. Заголовок - краткое описание
            ...
            
            Результаты должны быть релевантными и реалистичными.
            """
            
            headers = {
                "Authorization": f"Bearer {settings.openai_api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": "gpt-3.5-turbo",
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 1000,
                "temperature": 0.7
            }
            
            response = self.session.post(
                "https://api.openai.com/v1/chat/completions",
                headers=headers,
                json=data
            )
            
            if response.status_code == 200:
                result = response.json()
                return result["choices"][0]["message"]["content"]
            else:
                logger.error(f"OpenAI API error: {response.status_code} - {response.text}")
                return self.get_mock_serp(word, "openai")
                
        except Exception as e:
            logger.error(f"Ошибка запроса к OpenAI: {e}")
            return self.get_mock_serp(word, "openai")
    
    def get_mock_serp(self, word: str, llm_name: str) -> str:
        """Генерация mock SERP данных для тестирования"""
        mock_results = [
            f"1. {word.title()} Official Website - Официальный сайт {word}",
            f"2. Wikipedia: {word} - Энциклопедическая статья о {word}",
            f"3. {word} Reviews - Отзывы и рейтинги {word}",
            f"4. Buy {word} Online - Интернет-магазин {word}",
            f"5. {word} News - Последние новости о {word}",
            f"6. {word} Tutorial - Руководство по использованию {word}",
            f"7. {word} Comparison - Сравнение {word} с аналогами",
            f"8. {word} Forum - Форум пользователей {word}",
            f"9. {word} Support - Техническая поддержка {word}",
            f"10. {word} Blog - Блог о {word}"
        ]
        
        return "\n".join(mock_results) + f"\n\n[Generated by {llm_name}]"

    def extract_companies_simple(self, serp_content: str) -> list:
        """Простое извлечение компаний из SERP контента"""
        companies = []
        
        # Ищем строки, которые могут быть названиями компаний
        lines = serp_content.split('\n')
        for line in lines:
            # Ищем строки с точками (списки результатов)
            if re.match(r'^\d+\.', line.strip()):
                # Извлекаем название после номера
                match = re.search(r'^\d+\.\s*([^-]+)', line.strip())
                if match:
                    company_name = match.group(1).strip()
                    if len(company_name) > 2 and len(company_name) < 100:
                        companies.append(company_name)
        
        return companies[:10]  # Максимум 10 компаний

    def process_word_with_llm(self, word: Word, llm: LLM, db_session) -> bool:
        """Обработка одного слова с одним LLM провайдером"""
        try:
            # Проверяем, был ли уже запрос за последние 2 недели
            from datetime import timezone
            two_weeks_ago = datetime.now(timezone.utc) - timedelta(days=14)
            
            existing_serp = db_session.scalar(
                select(WordSerp).where(
                    WordSerp.word_id == word.uuid,
                    WordSerp.llm_id == llm.uuid,
                    WordSerp.create_time > two_weeks_ago
                )
            )
            
            if existing_serp:
                logger.info(f"SERP для слова '{word.name}' и LLM '{llm.name}' уже обновлен")
                return False
            
            logger.info(f"Получаем SERP для '{word.name}' от {llm.name}")
            
            # Получаем SERP данные синхронно
            if llm.name.lower() == "openai" and hasattr(settings, 'openai_api_key'):
                serp_content = self.get_serp_from_openai_sync(word.name)
            else:
                # Используем mock данные для остальных провайдеров
                serp_content = self.get_mock_serp(word.name, llm.name)
            
            # Сохраняем результат SERP
            word_serp = WordSerp(
                content=serp_content,
                llm_id=llm.uuid,
                word_id=word.uuid,
                create_time=datetime.now(timezone.utc)
            )
            
            db_session.add(word_serp)
            db_session.flush()  # Получаем ID для связи с компаниями
            
            # Извлекаем компании из SERP
            companies = self.extract_companies_simple(serp_content)
            
            # Сохраняем компании
            for company_name in companies:
                company = Company(
                    name=company_name,
                    serp_id=word_serp.uuid
                )
                db_session.add(company)
            
            db_session.commit()
            logger.info(f"Извлечено {len(companies)} компаний из SERP для слова '{word.name}'")
            
            return True
            
        except Exception as e:
            db_session.rollback()
            logger.error(f"Ошибка обработки слова '{word.name}' с LLM '{llm.name}': {e}")
            return False

    def analyze_brand_mentions_simple(self, serp_content: str, brand_name: str, competitor_names: list) -> dict:
        """Простой анализ упоминаний брендов без LLM"""
        content_lower = serp_content.lower()
        brand_lower = brand_name.lower()
        
        # Проверяем упоминание бренда
        brand_mentioned = brand_lower in content_lower
        brand_position = None
        if brand_mentioned:
            # Ищем позицию в списке результатов
            lines = serp_content.split('\n')
            for i, line in enumerate(lines, 1):
                if brand_lower in line.lower():
                    brand_position = i
                    break
        
        # Проверяем упоминания конкурентов
        competitor_mentioned = False
        mentioned_competitor = None
        competitor_position = None
        
        for competitor in competitor_names:
            if competitor.lower() in content_lower:
                competitor_mentioned = True
                mentioned_competitor = competitor
                # Ищем позицию конкурента
                lines = serp_content.split('\n')
                for i, line in enumerate(lines, 1):
                    if competitor.lower() in line.lower():
                        competitor_position = i
                        break
                break
        
        return {
            "brand_mentioned": brand_mentioned,
            "competitor_mentioned": competitor_mentioned,
            "mentioned_competitor": mentioned_competitor,
            "brand_position": brand_position,
            "competitor_position": competitor_position,
            "confidence": 90
        }

    def analyze_brand_mentions_for_serp(self, serp: WordSerp, db_session) -> bool:
        """Анализ упоминаний брендов в SERP результате"""
        try:
            # Получаем все brand проекты, которые могут быть связаны с этим словом
            word = db_session.scalar(select(Word).where(Word.uuid == serp.word_id))
            if not word or not word.group_id:
                return False
            
            # Ищем brand проект для этой группы
            brand_project = db_session.scalar(
                select(BrandProject).where(BrandProject.word_group_id == word.group_id)
            )
            
            if not brand_project:
                return False  # Это не brand проект
            
            # Получаем конкурентов проекта
            competitors = db_session.execute(
                select(Competitor).where(Competitor.project_id == brand_project.uuid)
            )
            competitor_names = [comp.name for comp in competitors.scalars().all()]
            
            # Упрощенный анализ упоминаний без LLM
            analysis_result = self.analyze_brand_mentions_simple(
                serp.content,
                brand_project.brand_name,
                competitor_names
            )
            
            # Сохраняем результат анализа
            brand_mention = BrandMention(
                serp_id=serp.uuid,
                project_id=brand_project.uuid,
                brand_mentioned=1 if analysis_result.get("brand_mentioned", False) else 0,
                competitor_mentioned=1 if analysis_result.get("competitor_mentioned", False) else 0,
                mentioned_competitor=analysis_result.get("mentioned_competitor"),
                brand_position=analysis_result.get("brand_position"),
                competitor_position=analysis_result.get("competitor_position"),
                analysis_confidence=analysis_result.get("confidence", 100)
            )
            
            db_session.add(brand_mention)
            db_session.commit()
            
            logger.info(f"Анализ упоминаний завершен для SERP {serp.uuid}")
            return True
            
        except Exception as e:
            db_session.rollback()
            logger.error(f"Ошибка анализа упоминаний для SERP {serp.uuid}: {e}")
            return False

    def run_worker_cycle(self):
        """Основной цикл воркера"""
        logger.info("🚀 Запуск цикла обновления SERP данных")
        
        with self.SessionLocal() as db_session:
            try:
                # Получаем все активные слова
                words = list(db_session.execute(
                    select(Word).where(Word.status == 1)
                ).scalars().all())
                
                # Получаем все активные LLM провайдеры
                llms = list(db_session.execute(
                    select(LLM).where(LLM.is_active == 1)
                ).scalars().all())
                
                logger.info(f"Найдено {len(words)} слов и {len(llms)} LLM провайдеров")
                
                processed_count = 0
                for word in words:
                    for llm in llms:
                        success = self.process_word_with_llm(word, llm, db_session)
                        if success:
                            processed_count += 1
                            
                            # После успешной обработки SERP, анализируем упоминания брендов
                            latest_serp = db_session.scalar(
                                select(WordSerp)
                                .where(WordSerp.word_id == word.uuid)
                                .where(WordSerp.llm_id == llm.uuid)
                                .order_by(WordSerp.create_time.desc())
                                .limit(1)
                            )
                            
                            if latest_serp:
                                self.analyze_brand_mentions_for_serp(latest_serp, db_session)
                
                logger.info(f"✅ Цикл завершен. Обработано {processed_count} комбинаций слово-LLM")
                
            except Exception as e:
                logger.error(f"❌ Ошибка в цикле воркера: {e}")

    def run_continuous(self, interval_hours: int = 24 * 14):  # 2 недели по умолчанию
        """Непрерывная работа воркера с заданным интервалом"""
        logger.info(f"Запуск непрерывного воркера с интервалом {interval_hours} часов")
        
        while True:
            try:
                self.run_worker_cycle()
                
                # Ждем до следующего цикла
                wait_seconds = interval_hours * 3600
                logger.info(f"Ожидание {interval_hours} часов до следующего цикла")
                time.sleep(wait_seconds)
                
            except KeyboardInterrupt:
                logger.info("Получен сигнал остановки воркера")
                break
            except Exception as e:
                logger.error(f"Критическая ошибка воркера: {str(e)}")
                # Ждем 1 час перед повторной попыткой
                time.sleep(3600)

# Глобальный экземпляр воркера
sync_llm_worker = SyncLLMWorker()

# Функция для запуска воркера
def start_sync_worker():
    """Запуск синхронного воркера"""
    sync_llm_worker.run_continuous()

if __name__ == "__main__":
    # Запуск воркера напрямую
    start_sync_worker()
